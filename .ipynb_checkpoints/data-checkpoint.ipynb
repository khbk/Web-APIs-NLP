{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9bc540ce",
   "metadata": {},
   "source": [
    "This Notebook is for creating my dataframe and saving as csv file so that i would not need to run it multiple times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b601cf70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ad023f4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KDRAMA 0\n",
      "1630642357\n",
      "KDRAMA 1\n",
      "1624735770\n",
      "KDRAMA 2\n",
      "1619615069\n",
      "KDRAMA 3\n",
      "1612367065\n",
      "KDRAMA 4\n",
      "1606752198\n",
      "KDRAMA 5\n",
      "1601785401\n",
      "KDRAMA 6\n",
      "1597302335\n",
      "KDRAMA 7\n",
      "1593644893\n",
      "KDRAMA 8\n",
      "1589930145\n",
      "KDRAMA 9\n",
      "1586556724\n",
      "KDRAMA 10\n",
      "1581570341\n",
      "KDRAMA 11\n",
      "1575322165\n",
      "KDRAMA 12\n",
      "1566253890\n",
      "KDRAMA 13\n",
      "1555565292\n",
      "KDRAMA 14\n",
      "1547959216\n",
      "kpop 0\n",
      "1633264994\n",
      "kpop 1\n",
      "1629714178\n",
      "kpop 2\n",
      "1625455318\n",
      "kpop 3\n",
      "1621174515\n",
      "kpop 4\n",
      "1617239630\n",
      "kpop 5\n",
      "1611927590\n",
      "kpop 6\n",
      "1608883685\n",
      "kpop 7\n",
      "1606239262\n",
      "kpop 8\n",
      "1600281097\n",
      "kpop 9\n",
      "1596053997\n",
      "kpop 10\n",
      "1590979073\n",
      "kpop 11\n",
      "1585659819\n",
      "kpop 12\n",
      "1580616819\n",
      "kpop 13\n",
      "1575523955\n",
      "kpop 14\n",
      "1571639738\n"
     ]
    }
   ],
   "source": [
    "subreddits = ['KDRAMA', 'kpop']\n",
    "dfs = []\n",
    "params = {\n",
    "            'subreddit': 'KDRAMA',\n",
    "            'q': 'best',\n",
    "            'size': 100,\n",
    "            # 'before': 1630597185\n",
    "        }\n",
    "\n",
    "for i in range(15):\n",
    "    print('KDRAMA', i)\n",
    "        # build your params to get the posts\n",
    "        # set before if i is not 0\n",
    "        # get the response using requests\n",
    "    url = 'https://api.pushshift.io/reddit/search/submission'\n",
    "    res = requests.get(url, params=params)\n",
    "        # turn the response into JSON\n",
    "    data = res.json()\n",
    "        # turn the JSON into a posts dataframe\n",
    "    posts = pd.DataFrame(data['data'])\n",
    "    params['before'] = posts['created_utc'].values[-1]\n",
    "        # narrow the df to just be the columns you care about\n",
    "    posts = posts[['author', 'id', 'score', 'subreddit', 'title', \n",
    "              'selftext', 'created_utc', 'num_comments']]\n",
    "        # append the dataframe to dfs\n",
    "    dfs.append(posts)\n",
    "        # dfs = pd.concat(dfs)\n",
    "    print(posts['created_utc'].values[-1])\n",
    "    time.sleep(3) # slow down three seconds in between each loop\n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "params2 = {\n",
    "            'subreddit': 'kpop',\n",
    "            'q': 'best',\n",
    "            'size': 100,\n",
    "            # 'before': 1630597185\n",
    "        }\n",
    "\n",
    "\n",
    "for i in range(15):\n",
    "    print('kpop', i)\n",
    "    # build your params to get the posts\n",
    "    # set before if i is not 0\n",
    "    # get the response using requests\n",
    "    url = 'https://api.pushshift.io/reddit/search/submission'\n",
    "    res = requests.get(url, params=params2)\n",
    "    # turn the response into JSON\n",
    "    data = res.json()\n",
    "    # turn the JSON into a posts dataframe\n",
    "    posts2 = pd.DataFrame(data['data'])\n",
    "    params2['before'] = posts2['created_utc'].values[-1]\n",
    "    # narrow the df to just be the columns you care about\n",
    "    posts2 = posts2[['author', 'id', 'score', 'subreddit', 'title', \n",
    "          'selftext', 'created_utc', 'num_comments']]\n",
    "    # append the dataframe to dfs\n",
    "    dfs.append(posts2)\n",
    "    # dfs = pd.concat(dfs)\n",
    "    print(posts2['created_utc'].values[-1])\n",
    "    time.sleep(3) # slow down three seconds in between each loop\n",
    "# pd.concat(dfs)\n",
    "\n",
    "dfs = pd.concat(dfs, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6272de68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 8)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9873bbae",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs.to_csv('reddit_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2837abb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    2727\n",
       "True      273\n",
       "Name: selftext, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(dfs['selftext'] == '[removed]').value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "49b7e4ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "author           0\n",
       "id               0\n",
       "score            0\n",
       "subreddit        0\n",
       "title            0\n",
       "selftext        13\n",
       "created_utc      0\n",
       "num_comments     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caf0dee9",
   "metadata": {},
   "source": [
    "Because there are 273 ['removed'] self texts and 13 nulls, I have increased our data to 3000 rows instead of 2000 rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8dde337d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I will perform some cleaning to get rid of the null and empty rows.\n",
    "dfs = dfs[dfs['selftext'] != '[removed]']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d6cf9af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = dfs.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ca95c5f",
   "metadata": {},
   "source": [
    "When looking at the dataframe once again, there were a a lot of '[deleted]' words as well. So, similar to '[removed]', I have dropped these rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "dbaa98c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = dfs[dfs['selftext'] != '[deleted]']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "53d73158",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs['selftext'].replace('', 'Nan', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "0038a618",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = dfs[dfs['selftext'] != 'Nan']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "38780e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs.to_csv('reddit_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ded577",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
